<script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\$','\$']]}
});
</script>

<h1>Example of a Lisp macro to implement Newton-Raphson algorithm.</h1>

<p>We introduce the Simplex algorithm, and the Newton-Raphson algorithm,
along with their implementations in Python and Clojure.</p>

<h2>Let's approximate $\sqrt{2}$!</h2>

<p>So let's set ourselves to calculate $\sqrt{2}$. It is defined as the
positive solution of $x^2=2$. Since the function $f:x\mapsto x^2$ is
strictly increasing over $\mathbb{R}^+$, the equation $f(x)=2,x\geq 0$
has only one solution, and since $f(1)=1&lt;2$ and $f(2)=4>2$, we know
that this solution is between $1$ and $2$. We now calculate
$f(1.5)=2.25>2$, so we have $1&lt;\sqrt{2}&lt;1.5$. We get a better
approximation by calculating $f(\frac{1+1.5}{2})=f(1.25)=1.5625&lt;2$ so
we know that $1.25&lt;\sqrt{2}&lt;1.5$. We could carry on like that forever,
but it will be faster to write a quick function to do that for us.
Let's do it in Python:</p>

<pre><code>def approx_sqrt_two(tol=0.00001,n_max=100):
    a,b = 1.0,2.0
    error = (b-a)/2
    n = 1
    while error &gt; tol and n &lt; n_max:
        candidate = (a+b)/2
        candidate_value = candidate**2
        if candidate_value &gt; 2:
            b = candidate
        else:
            a = candidate
        n += 1
        error = (b-a)/2
    return candidate
</code></pre>

<h2>A more generalized method</h2>

<p>The above code works well, but it can't be used to calculate any other
things that $\sqrt{2}$. The first thing we can do is tweak it so it
can calculate the square root of any number:</p>

<pre><code>def approx_sqrt(target,tol=0.00001,n_max=100):
    a,b = 1.0,target
    error = (b-a)/2
    n = 1
    while error &gt; tol and n &lt; n_max:
        candidate = (a+b)/2
        candidate_value = candidate**2
        if candidate_value &gt; target:
            b = candidate
        else:
            a = candidate
        n += 1
        error = (b-a)/2
    return candidate
</code></pre>

<p>So there it is, our new function <code>approx_sqrt</code> can calculate the
square root of any number. In fact we can do even better by enabling
our algorithm to be used for an arbitrary function.</p>

<p>What we want is to have a function with a signature <code>def
approx(func,target,tol=00001,n_max=100)</code> where <code>func</code> will be a lambda
expression. Here is a first try:</p>

<pre><code>def approx(func,target,a=0,b=100,tol=0.00001,n_max=100):
    error = (b-a)/2
    n = 1
    while error &gt; tol:
        candidate = (a+b)/2
        candidate_value = func(candidate)
        if candidate_value &gt; target:
            b = candidate
        else:
            a = candidate
        n += 1
        error = (b-a)/2
    return candidate
</code></pre>

<p>We now need to specify the bounds inside which the solution resides
(the arguments <code>a</code> and <code>b</code>), and also it assumes that <code>func</code> is
increasing (at the line <code>if candidate_value &gt; target:</code>). If we assume
<code>func</code> is monotonic (either always increasing or always decreasing) we
can make a small modification to that code where we guess whether
<code>func</code> is increasing or decreasing, by calculating the rate
$\displaystyle\frac{\text{func}(b)-\text{func}(a)}{b-a}$:</p>

<pre><code>def approx2(func,target,a=0,b=100,tol=0.00001,n_max=100):
    rate = (func(b)-func(a))/(b-a)
    compare = (lambda x,y: x &gt; y) if rate &gt; 0 else (lambda x,y: x &lt; y)
    error = (b-a)/2
    n = 1
    while error &gt; tol:
        candidate = (a+b)/2
        candidate_value = func(candidate)
        if compare(candidate_value, target):
            b = candidate
        else:
            a = candidate
        n += 1
        error = (b-a)/2
    return candidate
</code></pre>

<h2>A faster algorithm: Newton-Raphson</h2>

<p>Let us go back to the first problem and see how fast the first
algorithm performs to calculate $\sqrt{2}$. Is that algorithm
efficient? We make a small change in the first version of the code to
return how many iterations it required:</p>

<p>Can we do better? When searching for a better candidate that <code>a</code> and
<code>b</code>, the bisection algorithm takes the value
$\displaystyle\frac{a+b}{2}$. Taking the average is a reasonable
choice but it can seem a bit arbitrary, and that is where lies any
improvement of that algorithm. The algorithm of Newton-Raphson does
just that: it starts with $a$ as a first candidate, and then the
second candidate is calculated by solving: $f'(a)(x-a)-\text{target}=0$.</p>
